# ğŸ›£ï¸ AI ê¸°ë°˜ ë„ë¡œíŒŒì† ê°ì§€ ì‹œìŠ¤í…œ

[![Python](https://img.shields.io/badge/Python-3.8+-3776AB?logo=python)](https://www.python.org/)
[![YOLO](https://img.shields.io/badge/YOLO-11n-00FFFF?logo=yolo)](https://ultralytics.com/)
[![TensorFlow Lite](https://img.shields.io/badge/TensorFlow%20Lite-Quantized-FF6F00?logo=tensorflow)](https://www.tensorflow.org/lite)
[![SAM](https://img.shields.io/badge/SAM-Meta-1877F2?logo=meta)](https://segment-anything.com/)


> AI Hub ì§€ìì²´ ë„ë¡œ ì •ë¹„ ë°ì´í„°ë¥¼ í™œìš©í•œ ì´ì¤‘ ê²€ì¦ ë„ë¡œíŒŒì† ê°ì§€ ì‹œìŠ¤í…œ. ëª¨ë°”ì¼ ì˜¨ë””ë°”ì´ìŠ¤ Detectionê³¼ ì„œë²„ ê¸°ë°˜ SAM Segmentationì„ í†µí•œ ì •ë°€ ê²€ì¦ íŒŒì´í”„ë¼ì¸

## âœ¨ ë°ëª¨

- **ì‚¬ìš© ë°ì´í„°ì…‹:** [ì§€ìì²´ ë„ë¡œ ì •ë¹„ AI í•™ìŠµìš© ë°ì´í„°](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=&topMenu=&aihubDataSe=data&dataSetSn=557)

## ğŸ”– ëª©ì°¨

1. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
2. [ì£¼ìš” ê¸°ëŠ¥](#ì£¼ìš”-ê¸°ëŠ¥)
3. [ê¸°ìˆ  ìŠ¤íƒ](#ê¸°ìˆ -ìŠ¤íƒ)
4. [ì‹œì‘í•˜ê¸°](#ì‹œì‘í•˜ê¸°)
5. [ëª¨ë°”ì¼ìš© ëª¨ë¸ êµ¬ì¶•](#ëª¨ë°”ì¼ìš©-ëª¨ë¸-êµ¬ì¶•)
6. [ì„œë²„ìš© ëª¨ë¸ êµ¬ì¶•](#ì„œë²„ìš©-ëª¨ë¸-êµ¬ì¶•)
7. [í´ë” êµ¬ì¡°](#í´ë”-êµ¬ì¡°)
8. [ë¼ì´ì„ ìŠ¤](#ë¼ì´ì„ ìŠ¤)

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
ğŸ“± ëª¨ë°”ì¼ ë””ë°”ì´ìŠ¤ (1ì°¨ ê²€ì¶œ)
â”œâ”€â”€ YOLO11n Detection Model
â”œâ”€â”€ TensorFlow Lite (ì–‘ìí™”)
â””â”€â”€ ì‹¤ì‹œê°„ ë„ë¡œíŒŒì† ê°ì§€

         â¬‡ï¸ ì˜ì‹¬ êµ¬ê°„ ì „ì†¡

ğŸ–¥ï¸ GPU ì„œë²„ (2ì°¨ ì •ë°€ ê²€ì¦)
â”œâ”€â”€ YOLO11 Segmentation
â”œâ”€â”€ SAM (Segment Anything Model)
â””â”€â”€ ê³ ì •ë°€ë„ ë§ˆìŠ¤í¬ ìƒì„±
```

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

### ğŸ“± ëª¨ë°”ì¼ ì˜¨ë””ë°”ì´ìŠ¤ (1ì°¨ ê²€ì¶œ)
- **ê²½ëŸ‰ Detection**: YOLO11n ê¸°ë°˜ ì‹¤ì‹œê°„ ë„ë¡œíŒŒì† ê°ì§€
- **TensorFlow Lite**: Float16/Int8 ì–‘ìí™”ë¡œ ëª¨ë°”ì¼ ìµœì í™”
- **ë¹ ë¥¸ ì¶”ë¡ **: ê°¤ëŸ­ì‹œ ìŠ¤ë§ˆíŠ¸í°ì—ì„œ ì‹¤ì‹œê°„ ì²˜ë¦¬

### ğŸ–¥ï¸ ì„œë²„ ê¸°ë°˜ (2ì°¨ ì •ë°€ ê²€ì¦)
- **ê³ ì •ë°€ Segmentation**: YOLO11 + SAM ê²°í•© ëª¨ë¸
- **ì •ë°€ ë§ˆìŠ¤í¬ ìƒì„±**: Segment Anything Modelë¡œ í”½ì…€ ë‹¨ìœ„ ë¶„í• 
- **GPU ê°€ì†**: CUDA ê¸°ë°˜ ê³ ì„±ëŠ¥ ì²˜ë¦¬

### ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬
- **ì´ì¤‘ íŒŒì´í”„ë¼ì¸**: ëª¨ë°”ì¼ìš©/ì„œë²„ìš© ë³„ë„ ë°ì´í„° ë³€í™˜
- **ìŠ¤ë§ˆíŠ¸ ìƒ˜í”Œë§**: í¬íŠ¸í™€ ë¹„ìœ¨ ì¡°ì • ë° ë°ì´í„° ê· í˜• ìµœì í™”
- **ë³‘ë ¬ ì²˜ë¦¬**: ë©€í‹°í”„ë¡œì„¸ì‹±ì„ í†µí•œ ê³ ì† ë³€í™˜

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

| êµ¬ë¶„ | ëª¨ë°”ì¼ ì˜¨ë””ë°”ì´ìŠ¤ | ì„œë²„ ê¸°ë°˜ |
|:-----|:-----------------|:----------|
| **AI ëª¨ë¸** | YOLO11n Detection | YOLO11 Segmentation + SAM |
| **ìµœì í™”** | TensorFlow Lite | CUDA GPU ê°€ì† |
| **íƒ€ê²Ÿ í™˜ê²½** | Android/iOS | Linux GPU ì„œë²„ |
| **ì²˜ë¦¬ ë°©ì‹** | ì‹¤ì‹œê°„ ì¶”ë¡  | ë°°ì¹˜ ì •ë°€ ê²€ì¦ |

## ğŸš€ ì‹œì‘í•˜ê¸°

> Python 3.8 ì´ìƒ, CUDA 11.8+ (ì„œë²„ìš©)ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

```bash
# 1. ì €ì¥ì†Œ í´ë¡ 
git clone [repository-url]
cd ai-road-damage-detection

# 2. ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install ultralytics opencv-python numpy pillow
pip install tensorflow  # TFLite ë³€í™˜ìš©
pip install wandb       # ì‹¤í—˜ ì¶”ì ìš© (ì„ íƒì‚¬í•­)

# 4. SAM ê´€ë ¨ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì„œë²„ìš©)
pip install segment-anything
pip install torch torchvision  # CUDA ë²„ì „

# 5. SAM ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ë¡œë“œ
mkdir sam_models
cd sam_models
# ViT-B (ê¸°ë³¸, 375MB)
wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth
# ViT-L (í° ëª¨ë¸, 1.25GB)
wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth
# ViT-H (ìµœëŒ€ ëª¨ë¸, 2.56GB)
wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth
cd ..

# 6. AI Hub ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
# https://www.aihub.or.kr/aihubdata/data/view.do?dataSetSn=557
```

## ğŸ“± ëª¨ë°”ì¼ìš© ëª¨ë¸ êµ¬ì¶•

### ğŸ”„ ë°ì´í„° ì „ì²˜ë¦¬ (Detectionìš©)

```bash
# ê¸°ë³¸ COCO â†’ YOLO Detection ë³€í™˜
python mobile_data_converter.py --source_images_dir ./images --source_labels_dir ./labels

# ìƒ˜í”Œë§ ì˜µì…˜ í¬í•¨
python mobile_data_converter.py --source_images_dir ./images --source_labels_dir ./labels \
    --total_usage_ratio 0.5 --pothole_presence_ratio 0.3 \
    --split_ratios_train_val_test 0.7 0.2 0.1

# ê³ ê¸‰ ì˜µì…˜ (ë³‘ë ¬ ì²˜ë¦¬)
python mobile_data_converter.py --source_images_dir ./images --source_labels_dir ./labels \
    --output_dir ./mobile_dataset --num_workers 8 --seed 42
```

### ğŸ“ ëª¨ë°”ì¼ Detection ëª¨ë¸ í•™ìŠµ

```bash
# ê¸°ë³¸ í•™ìŠµ (ëª¨ë°”ì¼ ìµœì í™”)
python train_mobile_detection.py --data-yaml ./mobile_dataset/dataset.yaml --epochs 200

# ê²½ëŸ‰í™” ì¤‘ì‹¬ ì„¤ì •
python train_mobile_detection.py --data-yaml ./config/mobile_data.yaml \
    --model yolo11n.pt --epochs 300 --batch-size 128 \
    --img-size 640 --optimizer AdamW --device 0 \
    --wandb-project mobile_road_detection

# í´ë˜ìŠ¤ ì´ë¦„ ì„¤ì •
python train_mobile_detection.py --data-yaml ./dataset.yaml \
    --names 'ë„ë¡œê· ì—´,ë„ë¡œí™€' --epochs 150
```

### âš¡ TensorFlow Lite ì–‘ìí™”

```python
# quantize_yolo.py ì„¤ì • ìˆ˜ì •
PT_MODEL_PATH = './runs/detect/train/weights/best.pt'    # ëª¨ë°”ì¼ ëª¨ë¸ ê²½ë¡œ
OUTPUT_TFLITE_BASENAME = 'mobile_road_detection'         # ì¶œë ¥ íŒŒì¼ëª…
IMAGE_SIZE = 640                                         # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
QUANTIZATION_TYPE = 'int8'                              # ëª¨ë°”ì¼ ìµœì í™”

# ì‹¤í–‰
python quantize_yolo.py
```

## ğŸ–¥ï¸ ì„œë²„ìš© ëª¨ë¸ êµ¬ì¶•

### ğŸ­ ë°ì´í„° ì „ì²˜ë¦¬ (Segmentation + SAMìš©)

```bash
# ê¸°ë³¸ COCO â†’ YOLO Segmentation ë³€í™˜
python server_data_converter.py --input ./json_files --output ./server_dataset --image_dir ./images

# SAM ì ìš© ì •ë°€ ë³€í™˜
python server_data_converter.py --input ./annotations --output ./server_advanced \
    --image_dir ./raw_images --adaptive --workers 8 \
    --use_sam_for_potholes --sam_checkpoint_path ./sam_models/sam_vit_b_01ec64.pth \
    --sam_model_type vit_b --sam_device cuda

# ìƒ˜í”Œë§ í¬í•¨ ì„œë²„ìš© ë°ì´í„°ì…‹
python server_data_converter.py --input ./annotations --output ./server_sampled \
    --image_dir ./raw_images --sample_ratio 0.3 --target_pothole_ratio_in_sample 0.4 \
    --random_seed 42 --buffer 15.0
```

### ğŸ“ ì„œë²„ Segmentation ëª¨ë¸ í•™ìŠµ

```bash
# ê¸°ë³¸ ì„œë²„ ëª¨ë¸ í•™ìŠµ
python train_server_segmentation.py --data-dir ./server_dataset --names 'crack,pothole'

# W&B ë¡œê¹… í¬í•¨ ê³ ì„±ëŠ¥ í•™ìŠµ
python train_server_segmentation.py --data-dir ./server_dataset --names 'crack,pothole' \
    --wandb --wandb-project server-road-segmentation --epochs 300

# GPU ë‹¤ì¤‘ ì‚¬ìš© ê³ ì„±ëŠ¥ ì„¤ì •
python train_server_segmentation.py --data-dir ./server_dataset --names 'crack,pothole' \
    --model yolo11m-seg.pt --epochs 400 --batch-size 16 \
    --img-size 1024 --device 0,1,2,3 --workers 32
```

## ğŸ“ í´ë” êµ¬ì¡°

```
.
â”œâ”€â”€ ğŸ“± ëª¨ë°”ì¼ ì˜¨ë””ë°”ì´ìŠ¤ íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ mobile_data_converter.py      # COCO â†’ YOLO Detection ë³€í™˜
â”‚   â”œâ”€â”€ train_mobile_detection.py     # YOLO11n Detection í•™ìŠµ
â”‚   â””â”€â”€ quantize_yolo.py             # TensorFlow Lite ë³€í™˜ ë° ì–‘ìí™”
â”‚
â”œâ”€â”€ ğŸ–¥ï¸ ì„œë²„ ê¸°ë°˜ íŒŒì¼ë“¤
â”‚   â”œâ”€â”€ server_data_converter.py      # COCO â†’ YOLO Segmentation + SAM ë³€í™˜
â”‚   â””â”€â”€ train_server_segmentation.py  # YOLO11 Segmentation í•™ìŠµ
â”‚
â”œâ”€â”€ ğŸ“Š ë°ì´í„°ì…‹ êµ¬ì¡°
â”‚   â”œâ”€â”€ mobile_dataset/              # ëª¨ë°”ì¼ìš© Detection ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â”‚   â””â”€â”€ test/
â”‚   â”‚   â”œâ”€â”€ labels/                  # YOLO Detection í˜•ì‹
â”‚   â”‚   â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”‚   â”œâ”€â”€ val/
â”‚   â”‚   â”‚   â””â”€â”€ test/
â”‚   â”‚   â””â”€â”€ dataset.yaml
â”‚   â”‚
â”‚   â””â”€â”€ server_dataset/              # ì„œë²„ìš© Segmentation ë°ì´í„°
â”‚       â”œâ”€â”€ images/
â”‚       â”‚   â”œâ”€â”€ train/
â”‚       â”‚   â”œâ”€â”€ val/
â”‚       â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ labels/                  # YOLO Segmentation í˜•ì‹ (í´ë¦¬ê³¤)
â”‚       â”‚   â”œâ”€â”€ train/
â”‚       â”‚   â”œâ”€â”€ val/
â”‚       â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ dataset.yaml
â”‚
â”œâ”€â”€ ğŸ¤– ëª¨ë¸ ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ mobile_models/               # ëª¨ë°”ì¼ ë°°í¬ìš© ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ best.pt                  # PyTorch ì›ë³¸
â”‚   â”‚   â”œâ”€â”€ mobile_road_detection.tflite    # TFLite ì–‘ìí™” ëª¨ë¸
â”‚   â”‚   â””â”€â”€ model_info.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ server_models/               # ì„œë²„ ê²€ì¦ìš© ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ best.pt                  # YOLO Segmentation ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ last.pt
â”‚   â”‚   â””â”€â”€ validation_results.json
â”‚   â”‚
â”‚   â””â”€â”€ sam_models/                  # SAM ì²´í¬í¬ì¸íŠ¸
â”‚       â”œâ”€â”€ sam_vit_b_01ec64.pth     # ViT-B (375MB)
â”‚       â”œâ”€â”€ sam_vit_l_0b3195.pth     # ViT-L (1.25GB)
â”‚       â””â”€â”€ sam_vit_h_4b8939.pth     # ViT-H (2.56GB)
â”‚
â””â”€â”€ ğŸ“‹ í•™ìŠµ ê²°ê³¼
    â”œâ”€â”€ mobile_runs/                 # ëª¨ë°”ì¼ ëª¨ë¸ í•™ìŠµ ë¡œê·¸
    â”‚   â””â”€â”€ detect/
    â””â”€â”€ server_runs/                 # ì„œë²„ ëª¨ë¸ í•™ìŠµ ë¡œê·¸
        â””â”€â”€ segment/
```

## ğŸ”§ ì£¼ìš” íŒŒë¼ë¯¸í„° ë¹„êµ

### ğŸ“± ëª¨ë°”ì¼ìš© vs ğŸ–¥ï¸ ì„œë²„ìš©

| êµ¬ë¶„ | ëª¨ë°”ì¼ Detection | ì„œë²„ Segmentation |
|:-----|:----------------|:------------------|
| **ëª¨ë¸ í¬ê¸°** | ~6MB (INT8) | ~50MB+ |
| **ì…ë ¥ í¬ê¸°** | 640x640 | 896x896+ |
| **ë°°ì¹˜ í¬ê¸°** | 128 | 16 |
| **ì²˜ë¦¬ ì‹œê°„** | ~50ms | ~200ms |
| **ì •í™•ë„** | mAP50: 0.85+ | Mask mAP50: 0.90+ |

### ğŸ¯ SAM ëª¨ë¸ íƒ€ì…ë³„ íŠ¹ì„±

| ëª¨ë¸ | í¬ê¸° | VRAM | ì¶”ë¡  ì‹œê°„ | ì •í™•ë„ |
|:-----|:-----|:-----|:---------|:-------|
| **ViT-B** | 375MB | 4GB | ~1s | ë†’ìŒ |
| **ViT-L** | 1.25GB | 8GB | ~2s | ë§¤ìš° ë†’ìŒ |
| **ViT-H** | 2.56GB | 16GB | ~3s | ìµœê³  |

## ğŸ¯ ê°ì§€ í´ë˜ìŠ¤ ë° ì„±ëŠ¥

### ê°ì§€ ëŒ€ìƒ
- **Class 0**: ë„ë¡œê· ì—´ (Crack)
- **Class 1**: ë„ë¡œí™€ (Pothole)

### ì„±ëŠ¥ ì§€í‘œ

**ëª¨ë°”ì¼ Detection ëª¨ë¸**
- **mAP50**: 0.85+ (IoU 0.5ì—ì„œì˜ í‰ê·  ì •ë°€ë„)
- **mAP50-95**: 0.72+ (IoU 0.5-0.95ì—ì„œì˜ í‰ê·  ì •ë°€ë„)
- **ì¶”ë¡  ì†ë„**: 20 FPS (Galaxy S23)

**ì„œë²„ Segmentation ëª¨ë¸**
- **Mask mAP50**: 0.90+ (ë§ˆìŠ¤í¬ ê¸°ì¤€ í‰ê·  ì •ë°€ë„)
- **Box mAP50**: 0.92+ (ë°”ìš´ë”© ë°•ìŠ¤ ê¸°ì¤€ í‰ê·  ì •ë°€ë„)
- **SAM ì •ë°€ë„**: IoU 0.95+ (í”½ì…€ ë‹¨ìœ„ ë¶„í• )

## ğŸ–¥ï¸ ì„œë²„ í™˜ê²½ ìš”êµ¬ì‚¬í•­

### ìµœì†Œ ì‚¬ì–‘
- **GPU**: RTX 3060 (12GB VRAM)
- **RAM**: 16GB
- **CUDA**: 11.8+
- **Python**: 3.8+

### ê¶Œì¥ ì‚¬ì–‘
- **GPU**: RTX 4090 (24GB VRAM)
- **RAM**: 32GB
- **CUDA**: 12.0+
- **SSD**: 100GB+ ì—¬ìœ  ê³µê°„

## ğŸš§ ì•Œë ¤ì§„ ì´ìŠˆ ë° í•´ê²°ë°©ì•ˆ

### ëª¨ë°”ì¼ ëª¨ë¸
- **ë©”ëª¨ë¦¬ ë¶€ì¡±**: ë°°ì¹˜ í¬ê¸°ë¥¼ 64 ì´í•˜ë¡œ ì¡°ì •
- **ì •í™•ë„ ì €í•˜**: INT8 ëŒ€ì‹  Float16 ì–‘ìí™” ì‚¬ìš©
- **ì†ë„ ì €í•˜**: ì…ë ¥ í¬ê¸°ë¥¼ 320x320ìœ¼ë¡œ ì¶•ì†Œ

### ì„œë²„ ëª¨ë¸
- **CUDA OOM**: SAM ëª¨ë¸ íƒ€ì…ì„ ViT-Bë¡œ ë³€ê²½
- **SAM ì†ë„**: ë°°ì¹˜ ì²˜ë¦¬ ëŒ€ì‹  ê°œë³„ ì´ë¯¸ì§€ ì²˜ë¦¬
- **ë””ìŠ¤í¬ ê³µê°„**: ë¶ˆí•„ìš”í•œ ì¤‘ê°„ íŒŒì¼ ì •ê¸° ì‚­ì œ

## ğŸ”„ ì›Œí¬í”Œë¡œìš°

```bash
# 1ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„
python mobile_data_converter.py --source_images_dir ./raw_images --source_labels_dir ./raw_labels
python server_data_converter.py --input ./raw_labels --output ./server_data --image_dir ./raw_images --use_sam_for_potholes

# 2ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ
python train_mobile_detection.py --data-yaml ./mobile_dataset/dataset.yaml --epochs 200
python train_server_segmentation.py --data-dir ./server_dataset --epochs 300

# 3ë‹¨ê³„: ëª¨ë¸ ìµœì í™”
python quantize_yolo.py  # ëª¨ë°”ì¼ìš© TFLite ë³€í™˜

# 4ë‹¨ê³„: ë°°í¬
# ëª¨ë°”ì¼: mobile_road_detection.tflite â†’ Android/iOS ì•±
# ì„œë²„: server_models/best.pt â†’ GPU ì„œë²„ ë°°í¬
```
---

**AI ê¸°ë°˜ ë„ë¡œíŒŒì† ê°ì§€ ì‹œìŠ¤í…œ**ì€ ëª¨ë°”ì¼ ì‹¤ì‹œê°„ ê²€ì¶œê³¼ ì„œë²„ ì •ë°€ ê²€ì¦ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ AI ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.